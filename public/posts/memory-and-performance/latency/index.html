<!DOCTYPE html>
<html lang="en" dir="auto">

<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Memory and Performance: Latency | The purpose of knowledge is action.</title>
<meta name="keywords" content="go, rust, software-performance, profiling, memory, arm, cpu">
<meta name="description" content="Learn the importance of memory latency and how to reduce its impact. Identify how being memory aware (or unaware) affects performance.">
<meta name="author" content="Elvis S.">
<link rel="canonical" href="http://localhost:1313/posts/memory-and-performance/latency/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.93f625d739f1d6a5c6f20c146bc6a8d26b233492b34b2220c54b12fd46a04ded.css" integrity="sha256-k/Yl1znx1qXG8gwUa8ao0msjNJKzSyIgxUsS/UagTe0=" rel="preload stylesheet" as="style">
<link rel="icon" href="http://localhost:1313/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="http://localhost:1313/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="http://localhost:1313/favicon-32x32.png">
<link rel="apple-touch-icon" href="http://localhost:1313/apple-touch-icon.png">
<link rel="mask-icon" href="http://localhost:1313/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="http://localhost:1313/posts/memory-and-performance/latency/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><script type="application/ld+json">
    {
      "@context": "https://schema.org",
      "@type": "TechArticle",
      "headline": "Memory and Performance: Latency",
      "description": "Learn the importance of memory latency and how to reduce its impact. Identify how being memory aware (or unaware) affects performance.",
      "author": {
        "@type": "Person",
        "name": "Elvis S."
      },
      "datePublished": "2025-05-26",
      "dateModified": "2025-05-26",
      "mainEntityOfPage": "http:\/\/localhost:1313\/posts\/memory-and-performance\/latency\/",
      "publisher": {
        "@type": "Organization",
        "name": "The purpose of knowledge is action."
      }
    }
    </script>
    
    
    <meta name="robots" content="index, follow">
    <meta property="article:published_time" content="2025-05-26T10:33:25&#43;04:00">
    <meta property="article:modified_time" content="2025-05-26T10:33:25&#43;04:00"><meta property="og:url" content="http://localhost:1313/posts/memory-and-performance/latency/">
  <meta property="og:site_name" content="The purpose of knowledge is action.">
  <meta property="og:title" content="Memory and Performance: Latency">
  <meta property="og:description" content="Learn the importance of memory latency and how to reduce its impact. Identify how being memory aware (or unaware) affects performance.">
  <meta property="og:locale" content="en-us">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2025-05-26T10:33:25+04:00">
    <meta property="article:modified_time" content="2025-05-26T10:33:25+04:00">
    <meta property="article:tag" content="Go">
    <meta property="article:tag" content="Rust">
    <meta property="article:tag" content="Software-Performance">
    <meta property="article:tag" content="Profiling">
    <meta property="article:tag" content="Memory">
    <meta property="article:tag" content="Arm">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Memory and Performance: Latency">
<meta name="twitter:description" content="Learn the importance of memory latency and how to reduce its impact. Identify how being memory aware (or unaware) affects performance.">


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "http://localhost:1313/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Memory and Performance: Latency",
      "item": "http://localhost:1313/posts/memory-and-performance/latency/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Memory and Performance: Latency",
  "name": "Memory and Performance: Latency",
  "description": "Learn the importance of memory latency and how to reduce its impact. Identify how being memory aware (or unaware) affects performance.",
  "keywords": [
    "go", "rust", "software-performance", "profiling", "memory", "arm", "cpu"
  ],
  "articleBody": "Memory latency is one of the factors impacting application performance. Join me on a quest to understand memory latency, how to measure it, and knowing when it can be improved.\nFor this type of posts people usually use C/C++ but I’m going to stick to Go and occasionally bring in Rust for comparison since I’m mostly using these two languages and I want to show you the tools available to you.\nWe’re going to mix in both top-down and bottom-up approaches in this series of blog posts. The goal of this series is to learn how to identify memory latency and act uppon those signals.\nCPU Primer CPUs can’t store data - they need to communicate with memory. There are different types of memory involved, each with different latencies:\nMemory Type Latency Size L1 Cache 1-3 cycles 32-64KB L2 Cache 10-25 cycles 256KB-1MB L3 Cache 40-75 cycles 8-32MB Main Memory (RAM) 200-400 cycles GBs SSD 50,000+ cycles TBs CPUs work in cycles. A CPU cycle, also known as a clock cycle or machine cycle, is the basic unit of time in a CPU. It represents one complete operation of the CPU’s internal clock.\nThe Instruction Pipeline Without pipeline optimization, CPU operations happen sequentially in this order:\nFetching - retrieving the instruction from memory Decoding - interpreting the instruction and determining required actions Executing - performing the operation specified by the instruction Memory Access (if needed) - fetching data from memory Write Back (if needed) - writing the result back to memory If each stage takes one clock cycle, a single instruction would take 5 cycles to complete. In a simple sequential model, processing 1000 instructions would take 5000 cycles.\nHow Pipelining Changes Everything CPU pipelining transforms instruction processing from a sequential to simultaneous. Instead of waiting for each instruction to complete entirely before starting next, the CPU divides instruction processing into discrete stages and processes them simultaneously.\nHere’s how it works: while one instruction is being executed (stage 3), the next instruction can be decoded (stage 2), and the one after that can be fetched (stage 1). This creates a pipeline where multiple instructions are “in flight” at different stages.\n1 2 3 4 5 Cycle 1: Fetch A Cycle 2: Fetch B, Decode A Cycle 3: Fetch C, Decode B, Execute A Cycle 4: Fetch D, Decode C, Execute B, Memory Access A Cycle 5: Fetch E, Decode D, Execute C, Memory Access B, Write Back A After the initial 5-cycle startup delay, the CPU completes one instruction per cycle instead of one every 5 cycles - a 5x improvement in throughput. Processing 1000 instructions now takes approximately 1004 cycles instead of 5000.\nPipeline Hazards and Memory Interaction The pipeline’s efficiency depends heavily on memory access patterns. Here’s some of the hazards that can disrupt the smooth flow:\nData Hazards occur if one instruction needs data that isn’t ready yet\nControl Hazards happen with branching (if statements, loops). The CPU doesn’t know which instruction to fetch next until the branch condition is evaluated. Modern CPUs use branch prediction to guess the outcome and speculatively execute instructions, but mispredictions cost a lof of cycles (pipeline flushes).\nCPU tries to prevent these hazards:\nKeep frequently used data close to the CPU in caches (L1, L2, L3) Guess what data it might need next and fetch it early (Prefetching) Rearrange instructions to avoid stalls (out-of-order execution) Example of pipeline stall\n1 2 3 4 5 6 7 8 Cycle 1: [Fetch ADD] Cycle 2: [Decode ADD] [Fetch LDR] Cycle 3: [Execute ADD] [Decode LDR] [Fetch ADD] Cycle 4: [Store ADD] [Execute LDR] [Decode ADD] ← Memory request starts Cycle 5: [STALL] [STALL] ← Waiting for memory Cycle 6: [STALL] [STALL] ← Still waiting... ... Cycle 304: [Store LDR] [Execute ADD] ← Finally got data! Memory Latency Let’s explore ways to identify memory latencies in Go.\nWe have two implementations of binary search tree. One implementation is recursive memory-unaware and second is memory-aware by keeping data in contagious block and having predictable access patterns.\nFull implementation can be found here: https://github.com/Elvis339/compiler.rs/code/memory-and-performance/cmd/memaccess/memaccess.go\nPointer Base BST\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 // node represents a traditional pointer-based binary search tree (BST) // Each node is allocated separately on the heap, creating scattered memory layout type node struct { value int // The stored value left *node // Pointer to left child (smaller values) right *node // Pointer to right child (larger values) } // insert recursively adds a value to the BST func (n *node) insert(val int) *node { if n == nil { // Heap allocation: creates new node at unpredictable memory address // Depending on the use-case but for this specific use case of where we have search // this creates poor spatial locality return \u0026node{value: val} } if val \u003c n.value { n.left = n.left.insert(val) } else if val \u003e n.value { n.right = n.right.insert(val) } return n } // search traverses the BST following pointer chains // Each pointer dereference (n.left, n.right) likely causes cache miss // due to scattered memory layout of nodes func (n *node) search(val int) bool { if n == nil { return false } if val == n.value { return true } if val \u003c n.value { // Follow left pointer - random memory jump, likely cache miss return n.left.search(val) } // Follow right pointer - random memory jump, likely cache miss return n.right.search(val) } Contiguous BST\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 // contiguousBST implements BST using array-based heap indexing // All data stored in contiguous memory for better spatial locality // Uses heap property: parent at i, left child at 2*i+1, right child at 2*i+2 type contiguousBST struct { data []int // Contiguous array storing all values used []bool // Tracks which array positions are occupied size int // Current number of elements } func newContiguousBST(size int) *contiguousBST { return \u0026contiguousBST{ data: make([]int, size), used: make([]bool, size), size: 0, } } // insert adds value using array indexing instead of pointer following // Uses arithmetic (2*i+1, 2*i+2) instead of pointer dereferencing // Accesses predictable memory locations - cache-friendly func (cbst *contiguousBST) insert(val int) { if cbst.size == 0 { // First element goes at root (index 0) cbst.data[0] = val cbst.used[0] = true cbst.size++ return } index := 0 l := len(cbst.data) for { if index \u003e= l { return } if !cbst.used[index] { cbst.used[index] = true cbst.data[index] = val cbst.size++ return } // Navigate using heap indexing (arithmetic, no pointer dereferencing) if val \u003c cbst.data[index] { index = 2*index + 1 // Left child index calculation } else if val \u003e cbst.data[index] { index = 2*index + 2 // Right child index calculation } else { return // Duplicate value } } } // search traverses BST using array indexing instead of pointer chasing // Each access is to predictable memory location within contiguous array // Much more cache-friendly than random pointer dereferencing func (cbst *contiguousBST) search(val int) bool { index := 0 l := len(cbst.data) for index \u003c l \u0026\u0026 cbst.used[index] { if val == cbst.data[index] { return true } // Navigate using arithmetic instead of pointer dereferencing if val \u003c cbst.data[index] { index = 2*index + 1 // Left child - simple calculation } else { index = 2*index + 2 // Right child - simple calculation } } return false } Analysis This benchmark compares two Binary Search Tree implementations a traditional pointer-based approach versus a contiguous array-based approach. The contiguous implementation demonstrates 53% better performance despite using significantly more memory.\nImplementation Avg Time/Op Memory Used Allocations Performance Gain PointerBST 279.54 ms ~600 KB ~25,000 Baseline ContiguousBST 128.91 ms ~9 MB 2 53% faster The reason for ~2.17x improvement partially comes from not having recursive calls, the burden of function setup is heavy. Additionally as previously described we’re experiencing better spatial locality. Let’s dive deeper into the specific performance factors:\nModern CPUs fetch memory in cache lines (typically 64 bytes). When you request one byte, the CPU automatically fetches the entire cache line:\n1 2 3 4 5 6 7 8 9 // Pointer BST - each node scattered in memory node1 at 0x1000 // Cache line 1 node2 at 0x5000 // Cache line 2 (different, far away) node3 at 0x9000 // Cache line 3 (different, far away) // Array BST - multiple values in same cache line data[0] at 0x2000 // Cache line 1 data[1] at 0x2008 // Cache line 1 (same cache line!) data[2] at 0x2016 // Cache line 1 (same cache line!) CPUs have automatic hardware prefetchers that detect sequential access patterns:\n1 2 3 4 5 // Predictable sequential array access pattern data[0] → data[1] → data[2] → data[3] // Unpredictable pointer chaising trought the heap access pattern nodeA → nodeX → nodeM → nodeB Tools Unfortunately, Go’s pprof tool doesn’t provide clear insights into memory access patterns for this type of performance analysis. For deeper memory latency investigation, we need to examine the actual CPU instructions generated.\nWhile perf on Linux provides excellent memory profiling capabilities, we’ll use assembly analysis to understand the performance differences:\nAssembly script.\nAssembly Reveals the Truth The ARM assembly output shows exactly why the array BST is faster:\nPointer BST - Random memory access:\n1 2 ldr x0, [x0, #8] # Load n.left from random heap address bl search_function # Function call overhead + stack management Array BST - Predictable arithmetic:\n1 2 3 lsl x2, x2, #1 # index = index * 2 (bit shift) add x2, x2, #1 # index = 2*index + 1 (simple addition) b loop_start # Jump back to loop (no function calls) The key insights that assembly proves is that the memory layour affects the fundamental CPU instructions generated. Better spatial locality translates directly to more efficient machine code.\nConclusion Modern CPUs are incredibly fast, but their performance depends on keeping the instruction pipeline fed with data. Modern hardware and compilers have techniques to avoid pipeline stalls, but we as software engineers must understand abstractions below and help with the optimization.\nCPUs access data through multiple cache levels (L1, L2, L3) before reaching main memory. Understanding this hierarchy helps explain why some code runs faster than others. Accessing nearby memory locations allows hardware prefetchers to predict patterns and keep data flowing to the CPU. Sequential array access leverages cache lines efficiently, while scattered pointer chasing defeats these optimizations entirely. This is why in specific cases arrays outpreform maps. Being memory-aware means:\nChoosing data structures that promote spatial locality (arrays vs linked lists) Understanding how your data layout affects cache behavior Recognizing that algorithm complexity isn’t everything - you must include memory access into the mix Tools for analysis: While profilers like Go’s pprof show where time is spent, they don’t reveal memory access patterns. Assembly analysis helps understand the actual CPU instructions generated. On macOS, Instruments provides memory profiling capabilities, though it’s more valuable for higher-level analysis than micro-optimizations.\nOur BST comparison proved that identical algorithms with different memory layouts produce fundamentally different performance characteristics.\nWhat’s next? In the following blog post series, we’ll analyze Go’s experimental Green Tea garbage collector, which applies these same spatial locality principles to automatic memory management.\n",
  "wordCount" : "1965",
  "inLanguage": "en",
  "datePublished": "2025-05-26T10:33:25+04:00",
  "dateModified": "2025-05-26T10:33:25+04:00",
  "author":{
    "@type": "Person",
    "name": "Elvis S."
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "http://localhost:1313/posts/memory-and-performance/latency/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "The purpose of knowledge is action.",
    "logo": {
      "@type": "ImageObject",
      "url": "http://localhost:1313/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="http://localhost:1313/" accesskey="h" title="The purpose of knowledge is action. (Alt + H)">The purpose of knowledge is action.</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)" aria-label="Toggle theme">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="http://localhost:1313/categories/" title="categories">
                    <span>categories</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/tags/" title="tags">
                    <span>tags</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/archives/" title="archives">
                    <span>archives</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="http://localhost:1313/">Home</a>&nbsp;»&nbsp;<a href="http://localhost:1313/posts/">Posts</a></div>
    <h1 class="post-title entry-hint-parent">
      Memory and Performance: Latency
    </h1>
    <div class="post-description">
      Learn the importance of memory latency and how to reduce its impact. Identify how being memory aware (or unaware) affects performance.
    </div>
    <div class="post-meta"><span title='2025-05-26 10:33:25 +0400 +04'>May 26, 2025</span>&nbsp;·&nbsp;10 min&nbsp;·&nbsp;1965 words&nbsp;·&nbsp;Elvis S.

</div>
  </header> <div class="toc">
    <details >
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">Table of Contents</span>
        </summary>

        <div class="inner"><ul>
                <li>
                    <a href="#cpu-primer" aria-label="CPU Primer">CPU Primer</a><ul>
                        
                <li>
                    <a href="#the-instruction-pipeline" aria-label="The Instruction Pipeline">The Instruction Pipeline</a></li>
                <li>
                    <a href="#how-pipelining-changes-everything" aria-label="How Pipelining Changes Everything">How Pipelining Changes Everything</a></li>
                <li>
                    <a href="#pipeline-hazards-and-memory-interaction" aria-label="Pipeline Hazards and Memory Interaction">Pipeline Hazards and Memory Interaction</a></li></ul>
                </li>
                <li>
                    <a href="#memory-latency" aria-label="Memory Latency">Memory Latency</a><ul>
                        
                <li>
                    <a href="#analysis" aria-label="Analysis">Analysis</a></li></ul>
                </li>
                <li>
                    <a href="#tools" aria-label="Tools">Tools</a><ul>
                        
                <li>
                    <a href="#assembly-reveals-the-truth" aria-label="Assembly Reveals the Truth">Assembly Reveals the Truth</a></li></ul>
                </li>
                <li>
                    <a href="#conclusion" aria-label="Conclusion">Conclusion</a><ul>
                        
                <li>
                    <a href="#whats-next" aria-label="What&rsquo;s next?">What&rsquo;s next?</a>
                </li>
            </ul>
            </li>
            </ul>
        </div>
    </details>
</div>

  <div class="post-content"><p>Memory latency is one of the factors impacting application performance. Join me on a quest to understand memory latency, how to measure it, and knowing when it can be improved.</p>
<p>For this type of posts people usually use C/C++ but I&rsquo;m going to stick to Go and occasionally bring in Rust for comparison since I&rsquo;m mostly using these two languages and I want to show you the tools available to you.</p>
<p>We&rsquo;re going to mix in both top-down and bottom-up approaches in this series of blog posts. The goal of this series is to learn how to identify memory latency and act uppon those signals.</p>
<h1 id="cpu-primer">CPU Primer<a hidden class="anchor" aria-hidden="true" href="#cpu-primer">#</a></h1>
<p>CPUs can&rsquo;t store data - they need to communicate with memory. There are different types of memory involved, each with different latencies:</p>
<table>
  <thead>
      <tr>
          <th>Memory Type</th>
          <th>Latency</th>
          <th>Size</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>L1 Cache</td>
          <td>1-3 cycles</td>
          <td>32-64KB</td>
      </tr>
      <tr>
          <td>L2 Cache</td>
          <td>10-25 cycles</td>
          <td>256KB-1MB</td>
      </tr>
      <tr>
          <td>L3 Cache</td>
          <td>40-75 cycles</td>
          <td>8-32MB</td>
      </tr>
      <tr>
          <td>Main Memory (RAM)</td>
          <td>200-400 cycles</td>
          <td>GBs</td>
      </tr>
      <tr>
          <td>SSD</td>
          <td>50,000+ cycles</td>
          <td>TBs</td>
      </tr>
  </tbody>
</table>
<p>CPUs work in cycles. A CPU cycle, also known as a clock cycle or machine cycle, is the basic unit of time in a CPU. It represents one complete operation of the CPU&rsquo;s internal clock.</p>
<h2 id="the-instruction-pipeline">The Instruction Pipeline<a hidden class="anchor" aria-hidden="true" href="#the-instruction-pipeline">#</a></h2>
<p>Without pipeline optimization, CPU operations happen sequentially in this order:</p>
<ol>
<li><strong>Fetching</strong> - retrieving the instruction from memory</li>
<li><strong>Decoding</strong> - interpreting the instruction and determining required actions</li>
<li><strong>Executing</strong> - performing the operation specified by the instruction</li>
<li><strong>Memory Access</strong> (if needed) - fetching data from memory</li>
<li><strong>Write Back</strong> (if needed) - writing the result back to memory</li>
</ol>
<p>If each stage takes one clock cycle, a single instruction would take 5 cycles to complete. In a simple sequential model, processing 1000 instructions would take 5000 cycles.</p>
<h2 id="how-pipelining-changes-everything">How Pipelining Changes Everything<a hidden class="anchor" aria-hidden="true" href="#how-pipelining-changes-everything">#</a></h2>
<p>CPU pipelining transforms instruction processing from a sequential to simultaneous. Instead of waiting for each instruction to complete entirely before starting next, the CPU divides instruction processing into discrete stages and processes them simultaneously.</p>
<p>Here&rsquo;s how it works: while one instruction is being executed (stage 3), the next instruction can be decoded (stage 2), and the one after that can be fetched (stage 1). This creates a pipeline where multiple instructions are &ldquo;in flight&rdquo; at different stages.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">Cycle 1: Fetch A
</span></span><span class="line"><span class="cl">Cycle 2: Fetch B, Decode A  
</span></span><span class="line"><span class="cl">Cycle 3: Fetch C, Decode B, Execute A
</span></span><span class="line"><span class="cl">Cycle 4: Fetch D, Decode C, Execute B, Memory Access A
</span></span><span class="line"><span class="cl">Cycle 5: Fetch E, Decode D, Execute C, Memory Access B, Write Back A
</span></span></code></pre></td></tr></table>
</div>
</div><p>After the initial 5-cycle startup delay, the CPU completes one instruction per cycle instead of one every 5 cycles - a 5x improvement in throughput. Processing 1000 instructions now takes approximately 1004 cycles instead of 5000.</p>
<h2 id="pipeline-hazards-and-memory-interaction">Pipeline Hazards and Memory Interaction<a hidden class="anchor" aria-hidden="true" href="#pipeline-hazards-and-memory-interaction">#</a></h2>
<p>The pipeline&rsquo;s efficiency depends heavily on memory access patterns. Here&rsquo;s some of the hazards that can disrupt the smooth flow:</p>
<p><strong>Data Hazards</strong> occur if one instruction needs data that isn’t ready yet</p>
<p><strong>Control Hazards</strong> happen with branching (if statements, loops). The CPU doesn&rsquo;t know which instruction to fetch next until the branch condition is evaluated. Modern CPUs use branch prediction to guess the outcome and speculatively execute instructions, but mispredictions cost a lof of cycles (pipeline flushes).</p>
<p>CPU tries to prevent these hazards:</p>
<ol>
<li>Keep frequently used data close to the CPU in caches (L1, L2, L3)</li>
<li>Guess what data it might need next and fetch it early (Prefetching)</li>
<li>Rearrange instructions to avoid stalls (out-of-order execution)</li>
</ol>
<p><strong>Example of pipeline stall</strong></p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">Cycle 1: [Fetch ADD] 
</span></span><span class="line"><span class="cl">Cycle 2: [Decode ADD] [Fetch LDR]
</span></span><span class="line"><span class="cl">Cycle 3: [Execute ADD] [Decode LDR] [Fetch ADD]
</span></span><span class="line"><span class="cl">Cycle 4: [Store ADD] [Execute LDR] [Decode ADD] ← Memory request starts
</span></span><span class="line"><span class="cl">Cycle 5:             [STALL] [STALL] ← Waiting for memory
</span></span><span class="line"><span class="cl">Cycle 6:             [STALL] [STALL] ← Still waiting...
</span></span><span class="line"><span class="cl">...
</span></span><span class="line"><span class="cl">Cycle 304:           [Store LDR] [Execute ADD] ← Finally got data!
</span></span></code></pre></td></tr></table>
</div>
</div><h1 id="memory-latency">Memory Latency<a hidden class="anchor" aria-hidden="true" href="#memory-latency">#</a></h1>
<p>Let&rsquo;s explore ways to identify memory latencies in Go.</p>
<p>We have two implementations of binary search tree. One implementation is recursive memory-unaware and second is memory-aware by keeping data in contagious block and having predictable access patterns.</p>
<p>Full implementation can be found here: <a href="https://github.com/Elvis339/compiler.rs/code/memory-and-performance/cmd/memaccess/memaccess.go">https://github.com/Elvis339/compiler.rs/code/memory-and-performance/cmd/memaccess/memaccess.go</a></p>
<p><strong>Pointer Base BST</strong></p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span><span class="lnt">42
</span><span class="lnt">43
</span><span class="lnt">44
</span><span class="lnt">45
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-go" data-lang="go"><span class="line"><span class="cl"><span class="c1">// node represents a traditional pointer-based binary search tree (BST)</span>
</span></span><span class="line"><span class="cl"><span class="c1">// Each node is allocated separately on the heap, creating scattered memory layout</span>
</span></span><span class="line"><span class="cl"><span class="kd">type</span> <span class="nx">node</span> <span class="kd">struct</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">	<span class="nx">value</span> <span class="kt">int</span>   <span class="c1">// The stored value</span>
</span></span><span class="line"><span class="cl">	<span class="nx">left</span>  <span class="o">*</span><span class="nx">node</span> <span class="c1">// Pointer to left child (smaller values)</span>
</span></span><span class="line"><span class="cl">	<span class="nx">right</span> <span class="o">*</span><span class="nx">node</span> <span class="c1">// Pointer to right child (larger values)</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">// insert recursively adds a value to the BST</span>
</span></span><span class="line"><span class="cl"><span class="kd">func</span> <span class="p">(</span><span class="nx">n</span> <span class="o">*</span><span class="nx">node</span><span class="p">)</span> <span class="nf">insert</span><span class="p">(</span><span class="nx">val</span> <span class="kt">int</span><span class="p">)</span> <span class="o">*</span><span class="nx">node</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">	<span class="k">if</span> <span class="nx">n</span> <span class="o">==</span> <span class="kc">nil</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">		<span class="c1">// Heap allocation: creates new node at unpredictable memory address</span>
</span></span><span class="line"><span class="cl">		<span class="c1">// Depending on the use-case but for this specific use case of where we have search</span>
</span></span><span class="line"><span class="cl">		<span class="c1">// this creates poor spatial locality</span>
</span></span><span class="line"><span class="cl">		<span class="k">return</span> <span class="o">&amp;</span><span class="nx">node</span><span class="p">{</span><span class="nx">value</span><span class="p">:</span> <span class="nx">val</span><span class="p">}</span>
</span></span><span class="line"><span class="cl">	<span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">	<span class="k">if</span> <span class="nx">val</span> <span class="p">&lt;</span> <span class="nx">n</span><span class="p">.</span><span class="nx">value</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">		<span class="nx">n</span><span class="p">.</span><span class="nx">left</span> <span class="p">=</span> <span class="nx">n</span><span class="p">.</span><span class="nx">left</span><span class="p">.</span><span class="nf">insert</span><span class="p">(</span><span class="nx">val</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">	<span class="p">}</span> <span class="k">else</span> <span class="k">if</span> <span class="nx">val</span> <span class="p">&gt;</span> <span class="nx">n</span><span class="p">.</span><span class="nx">value</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">		<span class="nx">n</span><span class="p">.</span><span class="nx">right</span> <span class="p">=</span> <span class="nx">n</span><span class="p">.</span><span class="nx">right</span><span class="p">.</span><span class="nf">insert</span><span class="p">(</span><span class="nx">val</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">	<span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">	<span class="k">return</span> <span class="nx">n</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">// search traverses the BST following pointer chains</span>
</span></span><span class="line"><span class="cl"><span class="c1">// Each pointer dereference (n.left, n.right) likely causes cache miss</span>
</span></span><span class="line"><span class="cl"><span class="c1">// due to scattered memory layout of nodes</span>
</span></span><span class="line"><span class="cl"><span class="kd">func</span> <span class="p">(</span><span class="nx">n</span> <span class="o">*</span><span class="nx">node</span><span class="p">)</span> <span class="nf">search</span><span class="p">(</span><span class="nx">val</span> <span class="kt">int</span><span class="p">)</span> <span class="kt">bool</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">	<span class="k">if</span> <span class="nx">n</span> <span class="o">==</span> <span class="kc">nil</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">		<span class="k">return</span> <span class="kc">false</span>
</span></span><span class="line"><span class="cl">	<span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">	<span class="k">if</span> <span class="nx">val</span> <span class="o">==</span> <span class="nx">n</span><span class="p">.</span><span class="nx">value</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">		<span class="k">return</span> <span class="kc">true</span>
</span></span><span class="line"><span class="cl">	<span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">	<span class="k">if</span> <span class="nx">val</span> <span class="p">&lt;</span> <span class="nx">n</span><span class="p">.</span><span class="nx">value</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">		<span class="c1">// Follow left pointer - random memory jump, likely cache miss</span>
</span></span><span class="line"><span class="cl">		<span class="k">return</span> <span class="nx">n</span><span class="p">.</span><span class="nx">left</span><span class="p">.</span><span class="nf">search</span><span class="p">(</span><span class="nx">val</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">	<span class="p">}</span>
</span></span><span class="line"><span class="cl">	<span class="c1">// Follow right pointer - random memory jump, likely cache miss</span>
</span></span><span class="line"><span class="cl">	<span class="k">return</span> <span class="nx">n</span><span class="p">.</span><span class="nx">right</span><span class="p">.</span><span class="nf">search</span><span class="p">(</span><span class="nx">val</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p><strong>Contiguous BST</strong></p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span><span class="lnt">42
</span><span class="lnt">43
</span><span class="lnt">44
</span><span class="lnt">45
</span><span class="lnt">46
</span><span class="lnt">47
</span><span class="lnt">48
</span><span class="lnt">49
</span><span class="lnt">50
</span><span class="lnt">51
</span><span class="lnt">52
</span><span class="lnt">53
</span><span class="lnt">54
</span><span class="lnt">55
</span><span class="lnt">56
</span><span class="lnt">57
</span><span class="lnt">58
</span><span class="lnt">59
</span><span class="lnt">60
</span><span class="lnt">61
</span><span class="lnt">62
</span><span class="lnt">63
</span><span class="lnt">64
</span><span class="lnt">65
</span><span class="lnt">66
</span><span class="lnt">67
</span><span class="lnt">68
</span><span class="lnt">69
</span><span class="lnt">70
</span><span class="lnt">71
</span><span class="lnt">72
</span><span class="lnt">73
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-go" data-lang="go"><span class="line"><span class="cl"><span class="c1">// contiguousBST implements BST using array-based heap indexing</span>
</span></span><span class="line"><span class="cl"><span class="c1">// All data stored in contiguous memory for better spatial locality</span>
</span></span><span class="line"><span class="cl"><span class="c1">// Uses heap property: parent at i, left child at 2*i+1, right child at 2*i+2</span>
</span></span><span class="line"><span class="cl"><span class="kd">type</span> <span class="nx">contiguousBST</span> <span class="kd">struct</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">	<span class="nx">data</span> <span class="p">[]</span><span class="kt">int</span>  <span class="c1">// Contiguous array storing all values</span>
</span></span><span class="line"><span class="cl">	<span class="nx">used</span> <span class="p">[]</span><span class="kt">bool</span> <span class="c1">// Tracks which array positions are occupied</span>
</span></span><span class="line"><span class="cl">	<span class="nx">size</span> <span class="kt">int</span>    <span class="c1">// Current number of elements</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="kd">func</span> <span class="nf">newContiguousBST</span><span class="p">(</span><span class="nx">size</span> <span class="kt">int</span><span class="p">)</span> <span class="o">*</span><span class="nx">contiguousBST</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">	<span class="k">return</span> <span class="o">&amp;</span><span class="nx">contiguousBST</span><span class="p">{</span>
</span></span><span class="line"><span class="cl">		<span class="nx">data</span><span class="p">:</span> <span class="nb">make</span><span class="p">([]</span><span class="kt">int</span><span class="p">,</span> <span class="nx">size</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">		<span class="nx">used</span><span class="p">:</span> <span class="nb">make</span><span class="p">([]</span><span class="kt">bool</span><span class="p">,</span> <span class="nx">size</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">		<span class="nx">size</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">	<span class="p">}</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">// insert adds value using array indexing instead of pointer following</span>
</span></span><span class="line"><span class="cl"><span class="c1">// Uses arithmetic (2*i+1, 2*i+2) instead of pointer dereferencing</span>
</span></span><span class="line"><span class="cl"><span class="c1">// Accesses predictable memory locations - cache-friendly</span>
</span></span><span class="line"><span class="cl"><span class="kd">func</span> <span class="p">(</span><span class="nx">cbst</span> <span class="o">*</span><span class="nx">contiguousBST</span><span class="p">)</span> <span class="nf">insert</span><span class="p">(</span><span class="nx">val</span> <span class="kt">int</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">	<span class="k">if</span> <span class="nx">cbst</span><span class="p">.</span><span class="nx">size</span> <span class="o">==</span> <span class="mi">0</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">		<span class="c1">// First element goes at root (index 0)</span>
</span></span><span class="line"><span class="cl">		<span class="nx">cbst</span><span class="p">.</span><span class="nx">data</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="p">=</span> <span class="nx">val</span>
</span></span><span class="line"><span class="cl">		<span class="nx">cbst</span><span class="p">.</span><span class="nx">used</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="p">=</span> <span class="kc">true</span>
</span></span><span class="line"><span class="cl">		<span class="nx">cbst</span><span class="p">.</span><span class="nx">size</span><span class="o">++</span>
</span></span><span class="line"><span class="cl">		<span class="k">return</span>
</span></span><span class="line"><span class="cl">	<span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">	<span class="nx">index</span> <span class="o">:=</span> <span class="mi">0</span>
</span></span><span class="line"><span class="cl">	<span class="nx">l</span> <span class="o">:=</span> <span class="nb">len</span><span class="p">(</span><span class="nx">cbst</span><span class="p">.</span><span class="nx">data</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">	<span class="k">for</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">		<span class="k">if</span> <span class="nx">index</span> <span class="o">&gt;=</span> <span class="nx">l</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">			<span class="k">return</span>
</span></span><span class="line"><span class="cl">		<span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">		<span class="k">if</span> <span class="p">!</span><span class="nx">cbst</span><span class="p">.</span><span class="nx">used</span><span class="p">[</span><span class="nx">index</span><span class="p">]</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">			<span class="nx">cbst</span><span class="p">.</span><span class="nx">used</span><span class="p">[</span><span class="nx">index</span><span class="p">]</span> <span class="p">=</span> <span class="kc">true</span>
</span></span><span class="line"><span class="cl">			<span class="nx">cbst</span><span class="p">.</span><span class="nx">data</span><span class="p">[</span><span class="nx">index</span><span class="p">]</span> <span class="p">=</span> <span class="nx">val</span>
</span></span><span class="line"><span class="cl">			<span class="nx">cbst</span><span class="p">.</span><span class="nx">size</span><span class="o">++</span>
</span></span><span class="line"><span class="cl">			<span class="k">return</span>
</span></span><span class="line"><span class="cl">		<span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">		<span class="c1">// Navigate using heap indexing (arithmetic, no pointer dereferencing)</span>
</span></span><span class="line"><span class="cl">		<span class="k">if</span> <span class="nx">val</span> <span class="p">&lt;</span> <span class="nx">cbst</span><span class="p">.</span><span class="nx">data</span><span class="p">[</span><span class="nx">index</span><span class="p">]</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">			<span class="nx">index</span> <span class="p">=</span> <span class="mi">2</span><span class="o">*</span><span class="nx">index</span> <span class="o">+</span> <span class="mi">1</span> <span class="c1">// Left child index calculation</span>
</span></span><span class="line"><span class="cl">		<span class="p">}</span> <span class="k">else</span> <span class="k">if</span> <span class="nx">val</span> <span class="p">&gt;</span> <span class="nx">cbst</span><span class="p">.</span><span class="nx">data</span><span class="p">[</span><span class="nx">index</span><span class="p">]</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">			<span class="nx">index</span> <span class="p">=</span> <span class="mi">2</span><span class="o">*</span><span class="nx">index</span> <span class="o">+</span> <span class="mi">2</span> <span class="c1">// Right child index calculation</span>
</span></span><span class="line"><span class="cl">		<span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">			<span class="k">return</span> <span class="c1">// Duplicate value</span>
</span></span><span class="line"><span class="cl">		<span class="p">}</span>
</span></span><span class="line"><span class="cl">	<span class="p">}</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">// search traverses BST using array indexing instead of pointer chasing</span>
</span></span><span class="line"><span class="cl"><span class="c1">// Each access is to predictable memory location within contiguous array</span>
</span></span><span class="line"><span class="cl"><span class="c1">// Much more cache-friendly than random pointer dereferencing</span>
</span></span><span class="line"><span class="cl"><span class="kd">func</span> <span class="p">(</span><span class="nx">cbst</span> <span class="o">*</span><span class="nx">contiguousBST</span><span class="p">)</span> <span class="nf">search</span><span class="p">(</span><span class="nx">val</span> <span class="kt">int</span><span class="p">)</span> <span class="kt">bool</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">	<span class="nx">index</span> <span class="o">:=</span> <span class="mi">0</span>
</span></span><span class="line"><span class="cl">	<span class="nx">l</span> <span class="o">:=</span> <span class="nb">len</span><span class="p">(</span><span class="nx">cbst</span><span class="p">.</span><span class="nx">data</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">	<span class="k">for</span> <span class="nx">index</span> <span class="p">&lt;</span> <span class="nx">l</span> <span class="o">&amp;&amp;</span> <span class="nx">cbst</span><span class="p">.</span><span class="nx">used</span><span class="p">[</span><span class="nx">index</span><span class="p">]</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">		<span class="k">if</span> <span class="nx">val</span> <span class="o">==</span> <span class="nx">cbst</span><span class="p">.</span><span class="nx">data</span><span class="p">[</span><span class="nx">index</span><span class="p">]</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">			<span class="k">return</span> <span class="kc">true</span>
</span></span><span class="line"><span class="cl">		<span class="p">}</span>
</span></span><span class="line"><span class="cl">		<span class="c1">// Navigate using arithmetic instead of pointer dereferencing</span>
</span></span><span class="line"><span class="cl">		<span class="k">if</span> <span class="nx">val</span> <span class="p">&lt;</span> <span class="nx">cbst</span><span class="p">.</span><span class="nx">data</span><span class="p">[</span><span class="nx">index</span><span class="p">]</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">			<span class="nx">index</span> <span class="p">=</span> <span class="mi">2</span><span class="o">*</span><span class="nx">index</span> <span class="o">+</span> <span class="mi">1</span> <span class="c1">// Left child - simple calculation</span>
</span></span><span class="line"><span class="cl">		<span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">			<span class="nx">index</span> <span class="p">=</span> <span class="mi">2</span><span class="o">*</span><span class="nx">index</span> <span class="o">+</span> <span class="mi">2</span> <span class="c1">// Right child - simple calculation</span>
</span></span><span class="line"><span class="cl">		<span class="p">}</span>
</span></span><span class="line"><span class="cl">	<span class="p">}</span>
</span></span><span class="line"><span class="cl">	<span class="k">return</span> <span class="kc">false</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h2 id="analysis">Analysis<a hidden class="anchor" aria-hidden="true" href="#analysis">#</a></h2>
<p>This benchmark compares two Binary Search Tree implementations a traditional pointer-based approach versus a contiguous array-based approach. The contiguous implementation demonstrates <strong>53% better performance</strong> despite using significantly more memory.</p>
<table>
  <thead>
      <tr>
          <th>Implementation</th>
          <th>Avg Time/Op</th>
          <th>Memory Used</th>
          <th>Allocations</th>
          <th>Performance Gain</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>PointerBST</td>
          <td>279.54 ms</td>
          <td>~600 KB</td>
          <td>~25,000</td>
          <td>Baseline</td>
      </tr>
      <tr>
          <td>ContiguousBST</td>
          <td>128.91 ms</td>
          <td>~9 MB</td>
          <td>2</td>
          <td><strong>53% faster</strong></td>
      </tr>
  </tbody>
</table>
<p>The reason for ~2.17x improvement partially comes from not having recursive calls, the burden of function setup is heavy. Additionally as previously described we&rsquo;re experiencing better spatial locality. Let&rsquo;s dive deeper into the specific performance factors:</p>
<p>Modern CPUs fetch memory in <strong>cache lines</strong> (typically 64 bytes). When you request one byte, the CPU automatically fetches the entire cache line:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span><span class="lnt">9
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-go" data-lang="go"><span class="line"><span class="cl"><span class="c1">// Pointer BST - each node scattered in memory</span>
</span></span><span class="line"><span class="cl"><span class="nx">node1</span> <span class="nx">at</span> <span class="mh">0x1000</span>  <span class="c1">// Cache line 1</span>
</span></span><span class="line"><span class="cl"><span class="nx">node2</span> <span class="nx">at</span> <span class="mh">0x5000</span>  <span class="c1">// Cache line 2 (different, far away)</span>
</span></span><span class="line"><span class="cl"><span class="nx">node3</span> <span class="nx">at</span> <span class="mh">0x9000</span>  <span class="c1">// Cache line 3 (different, far away)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">// Array BST - multiple values in same cache line</span>
</span></span><span class="line"><span class="cl"><span class="nx">data</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="nx">at</span> <span class="mh">0x2000</span>  <span class="c1">// Cache line 1</span>
</span></span><span class="line"><span class="cl"><span class="nx">data</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="nx">at</span> <span class="mh">0x2008</span>  <span class="c1">// Cache line 1 (same cache line!)</span>
</span></span><span class="line"><span class="cl"><span class="nx">data</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="nx">at</span> <span class="mh">0x2016</span>  <span class="c1">// Cache line 1 (same cache line!)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>CPUs have automatic hardware prefetchers that detect sequential access patterns:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-go" data-lang="go"><span class="line"><span class="cl"><span class="c1">// Predictable sequential array access pattern</span>
</span></span><span class="line"><span class="cl"><span class="nx">data</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="err">→</span> <span class="nx">data</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="err">→</span> <span class="nx">data</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="err">→</span> <span class="nx">data</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">// Unpredictable pointer chaising trought the heap access pattern</span>
</span></span><span class="line"><span class="cl"><span class="nx">nodeA</span> <span class="err">→</span> <span class="nx">nodeX</span> <span class="err">→</span> <span class="nx">nodeM</span> <span class="err">→</span> <span class="nx">nodeB</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h1 id="tools">Tools<a hidden class="anchor" aria-hidden="true" href="#tools">#</a></h1>
<p>Unfortunately, Go&rsquo;s pprof tool doesn&rsquo;t provide clear insights into memory access patterns for this type of performance analysis. For deeper memory latency investigation, we need to examine the actual CPU instructions generated.</p>
<p>While <code>perf</code> on Linux provides excellent memory profiling capabilities, we&rsquo;ll use assembly analysis to understand the performance differences:</p>
<p><a href="https://github.com/Elvis339/compiler.rs/code/memory-and-performance/cmd/memaccess/demo/assembly.sh">Assembly script</a>.</p>
<h2 id="assembly-reveals-the-truth">Assembly Reveals the Truth<a hidden class="anchor" aria-hidden="true" href="#assembly-reveals-the-truth">#</a></h2>
<p>The ARM assembly output shows exactly why the array BST is faster:</p>
<p><strong>Pointer BST</strong> - Random memory access:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">ldr x0, [x0, #8]     # Load n.left from random heap address
</span></span><span class="line"><span class="cl">bl  search_function  # Function call overhead + stack management
</span></span></code></pre></td></tr></table>
</div>
</div><p><strong>Array BST</strong> - Predictable arithmetic:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">lsl x2, x2, #1       # index = index * 2 (bit shift)
</span></span><span class="line"><span class="cl">add x2, x2, #1       # index = 2*index + 1 (simple addition)
</span></span><span class="line"><span class="cl">b   loop_start       # Jump back to loop (no function calls)
</span></span></code></pre></td></tr></table>
</div>
</div><p>The key insights that assembly proves is that the memory layour affects the fundamental CPU instructions generated. Better spatial locality translates directly to more efficient machine code.</p>
<h1 id="conclusion">Conclusion<a hidden class="anchor" aria-hidden="true" href="#conclusion">#</a></h1>
<p>Modern CPUs are incredibly fast, but their performance depends on keeping the instruction pipeline fed with data. Modern hardware and compilers have techniques to avoid pipeline stalls, but we as software engineers must understand abstractions below and help with the optimization.</p>
<ul>
<li>CPUs access data through multiple cache levels (L1, L2, L3) before reaching main memory. Understanding this hierarchy helps explain why some code runs faster than others.</li>
<li>Accessing nearby memory locations allows hardware prefetchers to predict patterns and keep data flowing to the CPU. Sequential array access leverages cache lines efficiently, while scattered pointer chasing defeats these optimizations entirely. This is why in specific cases arrays outpreform maps.</li>
</ul>
<p><strong>Being memory-aware means:</strong></p>
<ul>
<li>Choosing data structures that promote spatial locality (arrays vs linked lists)</li>
<li>Understanding how your data layout affects cache behavior</li>
<li>Recognizing that algorithm complexity isn&rsquo;t everything - you must include memory access into the mix</li>
</ul>
<p><strong>Tools for analysis:</strong> While profilers like Go&rsquo;s pprof show where time is spent, they don&rsquo;t reveal memory access patterns. Assembly analysis helps understand the actual CPU instructions generated. On macOS, Instruments provides memory profiling capabilities, though it&rsquo;s more valuable for higher-level analysis than micro-optimizations.</p>
<p>Our BST comparison proved that identical algorithms with different memory layouts produce fundamentally different performance characteristics.</p>
<h2 id="whats-next">What&rsquo;s next?<a hidden class="anchor" aria-hidden="true" href="#whats-next">#</a></h2>
<p>In the following blog post series, we&rsquo;ll analyze Go&rsquo;s experimental <a href="https://github.com/golang/go/issues/73581">Green Tea</a> garbage collector, which applies these same spatial locality principles to automatic memory management.</p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="http://localhost:1313/tags/go/">Go</a></li>
      <li><a href="http://localhost:1313/tags/rust/">Rust</a></li>
      <li><a href="http://localhost:1313/tags/software-performance/">Software-Performance</a></li>
      <li><a href="http://localhost:1313/tags/profiling/">Profiling</a></li>
      <li><a href="http://localhost:1313/tags/memory/">Memory</a></li>
      <li><a href="http://localhost:1313/tags/arm/">Arm</a></li>
      <li><a href="http://localhost:1313/tags/cpu/">Cpu</a></li>
    </ul>


<ul class="share-buttons">
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Memory and Performance: Latency on x"
            href="https://x.com/intent/tweet/?text=Memory%20and%20Performance%3a%20Latency&amp;url=http%3a%2f%2flocalhost%3a1313%2fposts%2fmemory-and-performance%2flatency%2f&amp;hashtags=go%2crust%2csoftware-performance%2cprofiling%2cmemory%2carm%2ccpu">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M512 62.554 L 512 449.446 C 512 483.97 483.97 512 449.446 512 L 62.554 512 C 28.03 512 0 483.97 0 449.446 L 0 62.554 C 0 28.03 28.029 0 62.554 0 L 449.446 0 C 483.971 0 512 28.03 512 62.554 Z M 269.951 190.75 L 182.567 75.216 L 56 75.216 L 207.216 272.95 L 63.9 436.783 L 125.266 436.783 L 235.9 310.383 L 332.567 436.783 L 456 436.783 L 298.367 228.367 L 432.367 75.216 L 371.033 75.216 Z M 127.633 110 L 164.101 110 L 383.481 400.065 L 349.5 400.065 Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Memory and Performance: Latency on linkedin"
            href="https://www.linkedin.com/shareArticle?mini=true&amp;url=http%3a%2f%2flocalhost%3a1313%2fposts%2fmemory-and-performance%2flatency%2f&amp;title=Memory%20and%20Performance%3a%20Latency&amp;summary=Memory%20and%20Performance%3a%20Latency&amp;source=http%3a%2f%2flocalhost%3a1313%2fposts%2fmemory-and-performance%2flatency%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-288.985,423.278l0,-225.717l-75.04,0l0,225.717l75.04,0Zm270.539,0l0,-129.439c0,-69.333 -37.018,-101.586 -86.381,-101.586c-39.804,0 -57.634,21.891 -67.617,37.266l0,-31.958l-75.021,0c0.995,21.181 0,225.717 0,225.717l75.02,0l0,-126.056c0,-6.748 0.486,-13.492 2.474,-18.315c5.414,-13.475 17.767,-27.434 38.494,-27.434c27.135,0 38.007,20.707 38.007,51.037l0,120.768l75.024,0Zm-307.552,-334.556c-25.674,0 -42.448,16.879 -42.448,39.002c0,21.658 16.264,39.002 41.455,39.002l0.484,0c26.165,0 42.452,-17.344 42.452,-39.002c-0.485,-22.092 -16.241,-38.954 -41.943,-39.002Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Memory and Performance: Latency on reddit"
            href="https://reddit.com/submit?url=http%3a%2f%2flocalhost%3a1313%2fposts%2fmemory-and-performance%2flatency%2f&title=Memory%20and%20Performance%3a%20Latency">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-3.446,265.638c0,-22.964 -18.616,-41.58 -41.58,-41.58c-11.211,0 -21.361,4.457 -28.841,11.666c-28.424,-20.508 -67.586,-33.757 -111.204,-35.278l18.941,-89.121l61.884,13.157c0.756,15.734 13.642,28.29 29.56,28.29c16.407,0 29.706,-13.299 29.706,-29.701c0,-16.403 -13.299,-29.702 -29.706,-29.702c-11.666,0 -21.657,6.792 -26.515,16.578l-69.105,-14.69c-1.922,-0.418 -3.939,-0.042 -5.585,1.036c-1.658,1.073 -2.811,2.761 -3.224,4.686l-21.152,99.438c-44.258,1.228 -84.046,14.494 -112.837,35.232c-7.468,-7.164 -17.589,-11.591 -28.757,-11.591c-22.965,0 -41.585,18.616 -41.585,41.58c0,16.896 10.095,31.41 24.568,37.918c-0.639,4.135 -0.99,8.328 -0.99,12.576c0,63.977 74.469,115.836 166.33,115.836c91.861,0 166.334,-51.859 166.334,-115.836c0,-4.218 -0.347,-8.387 -0.977,-12.493c14.564,-6.47 24.735,-21.034 24.735,-38.001Zm-119.474,108.193c-20.27,20.241 -59.115,21.816 -70.534,21.816c-11.428,0 -50.277,-1.575 -70.522,-21.82c-3.007,-3.008 -3.007,-7.882 0,-10.889c3.003,-2.999 7.882,-3.003 10.885,0c12.777,12.781 40.11,17.317 59.637,17.317c19.522,0 46.86,-4.536 59.657,-17.321c3.016,-2.999 7.886,-2.995 10.885,0.008c3.008,3.011 3.003,7.882 -0.008,10.889Zm-5.23,-48.781c-16.373,0 -29.701,-13.324 -29.701,-29.698c0,-16.381 13.328,-29.714 29.701,-29.714c16.378,0 29.706,13.333 29.706,29.714c0,16.374 -13.328,29.698 -29.706,29.698Zm-160.386,-29.702c0,-16.381 13.328,-29.71 29.714,-29.71c16.369,0 29.689,13.329 29.689,29.71c0,16.373 -13.32,29.693 -29.689,29.693c-16.386,0 -29.714,-13.32 -29.714,-29.693Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Memory and Performance: Latency on facebook"
            href="https://facebook.com/sharer/sharer.php?u=http%3a%2f%2flocalhost%3a1313%2fposts%2fmemory-and-performance%2flatency%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-106.468,0l0,-192.915l66.6,0l12.672,-82.621l-79.272,0l0,-53.617c0,-22.603 11.073,-44.636 46.58,-44.636l36.042,0l0,-70.34c0,0 -32.71,-5.582 -63.982,-5.582c-65.288,0 -107.96,39.569 -107.96,111.204l0,62.971l-72.573,0l0,82.621l72.573,0l0,192.915l-191.104,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Memory and Performance: Latency on whatsapp"
            href="https://api.whatsapp.com/send?text=Memory%20and%20Performance%3a%20Latency%20-%20http%3a%2f%2flocalhost%3a1313%2fposts%2fmemory-and-performance%2flatency%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-58.673,127.703c-33.842,-33.881 -78.847,-52.548 -126.798,-52.568c-98.799,0 -179.21,80.405 -179.249,179.234c-0.013,31.593 8.241,62.428 23.927,89.612l-25.429,92.884l95.021,-24.925c26.181,14.28 55.659,21.807 85.658,21.816l0.074,0c98.789,0 179.206,-80.413 179.247,-179.243c0.018,-47.895 -18.61,-92.93 -52.451,-126.81Zm-126.797,275.782l-0.06,0c-26.734,-0.01 -52.954,-7.193 -75.828,-20.767l-5.441,-3.229l-56.386,14.792l15.05,-54.977l-3.542,-5.637c-14.913,-23.72 -22.791,-51.136 -22.779,-79.287c0.033,-82.142 66.867,-148.971 149.046,-148.971c39.793,0.014 77.199,15.531 105.329,43.692c28.128,28.16 43.609,65.592 43.594,105.4c-0.034,82.149 -66.866,148.983 -148.983,148.984Zm81.721,-111.581c-4.479,-2.242 -26.499,-13.075 -30.604,-14.571c-4.105,-1.495 -7.091,-2.241 -10.077,2.241c-2.986,4.483 -11.569,14.572 -14.182,17.562c-2.612,2.988 -5.225,3.364 -9.703,1.12c-4.479,-2.241 -18.91,-6.97 -36.017,-22.23c-13.314,-11.876 -22.304,-26.542 -24.916,-31.026c-2.612,-4.484 -0.279,-6.908 1.963,-9.14c2.016,-2.007 4.48,-5.232 6.719,-7.847c2.24,-2.615 2.986,-4.484 4.479,-7.472c1.493,-2.99 0.747,-5.604 -0.374,-7.846c-1.119,-2.241 -10.077,-24.288 -13.809,-33.256c-3.635,-8.733 -7.327,-7.55 -10.077,-7.688c-2.609,-0.13 -5.598,-0.158 -8.583,-0.158c-2.986,0 -7.839,1.121 -11.944,5.604c-4.105,4.484 -15.675,15.32 -15.675,37.364c0,22.046 16.048,43.342 18.287,46.332c2.24,2.99 31.582,48.227 76.511,67.627c10.685,4.615 19.028,7.371 25.533,9.434c10.728,3.41 20.492,2.929 28.209,1.775c8.605,-1.285 26.499,-10.833 30.231,-21.295c3.732,-10.464 3.732,-19.431 2.612,-21.298c-1.119,-1.869 -4.105,-2.99 -8.583,-5.232Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Memory and Performance: Latency on telegram"
            href="https://telegram.me/share/url?text=Memory%20and%20Performance%3a%20Latency&amp;url=http%3a%2f%2flocalhost%3a1313%2fposts%2fmemory-and-performance%2flatency%2f">
            <svg version="1.1" xml:space="preserve" viewBox="2 2 28 28" height="30px" width="30px" fill="currentColor">
                <path
                    d="M26.49,29.86H5.5a3.37,3.37,0,0,1-2.47-1,3.35,3.35,0,0,1-1-2.47V5.48A3.36,3.36,0,0,1,3,3,3.37,3.37,0,0,1,5.5,2h21A3.38,3.38,0,0,1,29,3a3.36,3.36,0,0,1,1,2.46V26.37a3.35,3.35,0,0,1-1,2.47A3.38,3.38,0,0,1,26.49,29.86Zm-5.38-6.71a.79.79,0,0,0,.85-.66L24.73,9.24a.55.55,0,0,0-.18-.46.62.62,0,0,0-.41-.17q-.08,0-16.53,6.11a.59.59,0,0,0-.41.59.57.57,0,0,0,.43.52l4,1.24,1.61,4.83a.62.62,0,0,0,.63.43.56.56,0,0,0,.4-.17L16.54,20l4.09,3A.9.9,0,0,0,21.11,23.15ZM13.8,20.71l-1.21-4q8.72-5.55,8.78-5.55c.15,0,.23,0,.23.16a.18.18,0,0,1,0,.06s-2.51,2.3-7.52,6.8Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Memory and Performance: Latency on ycombinator"
            href="https://news.ycombinator.com/submitlink?t=Memory%20and%20Performance%3a%20Latency&u=http%3a%2f%2flocalhost%3a1313%2fposts%2fmemory-and-performance%2flatency%2f">
            <svg version="1.1" xml:space="preserve" width="30px" height="30px" viewBox="0 0 512 512" fill="currentColor"
                xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape">
                <path
                    d="M449.446 0C483.971 0 512 28.03 512 62.554L512 449.446C512 483.97 483.97 512 449.446 512L62.554 512C28.03 512 0 483.97 0 449.446L0 62.554C0 28.03 28.029 0 62.554 0L449.446 0ZM183.8767 87.9921H121.8427L230.6673 292.4508V424.0079H281.3328V292.4508L390.1575 87.9921H328.1233L256 238.2489z" />
            </svg>
        </a>
    </li>
</ul>

  </footer>
</article>
    </main>
    
<footer class="footer">
        <span>&copy; 2025 <a href="http://localhost:1313/">The purpose of knowledge is action.</a></span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'copy';

        function copyingDone() {
            copybutton.innerHTML = 'copied!';
            setTimeout(() => {
                copybutton.innerHTML = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
